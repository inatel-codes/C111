print 1
print(1)
setwd("C:/Projects/Inatel/C111/Aula3_13_05_2020")
library(rv
library(stringr)
library(stringr)
library(dplyr)
library(lubridate)
library(readr)
install.packages('readr')
library(readr)
install.packages('vctrs')
library(readr)
install.packages('vctrs')
library(readr)
install.packages('lubridate')
library(lubridate)
library(dplyr)
library(stringr)
library(rvest)
paginaweb <- read_html("https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html")
paginaweb
resultados <- paginaweb %>% html_nodes(".short-desc")
resultados
registros <- vector("list", length = length(resultados))
registros
for (i in seq_along(resultados))
# repeticao de 180x
{
datas <- str_c(resultados[i] %>%
html_nodes("strong") %>%
html_text(trim = TRUE), ', 2017')
# para extrair a data, entre as tags strong, extrair o texto sem espacos adicionais
# antes/depois e trabalhar com o ano de 2017
mentira <- str_sub(xml_contents(resultados[i])[2] %>% html_text(trim = TRUE), 2, -2)
# para extrair a mentira com str_sub que extrai um string
explicacao <- str_sub(resultados[i] %>%
html_nodes(".short-truth") %>%
html_text(trim = TRUE), 2, -2)
# para extrair a explicacao com a mesma regra da data, apenas com short-truth
url <- resultados[i] %>% html_nodes("a") %>% html_attr("href")
# para extrair o link, usa-se a tag href que aponta para um linl HTML
registros[[i]] <- data_frame(datas = datas, mentira = mentira, explicacao = explicacao, url = url)
# e gravamos tudo como um dataframe; tudo que extraimos vamos gravar de volta
# ao objeto registros que eh uma lista
}
df <- bind_rows(registros)
df$datas <- mdy(df$datas)
write_csv(df, "mentiras_trump.csv")
df <- read_csv("mentiras_trump.csv")
View(df)
